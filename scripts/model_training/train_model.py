from sklearn import tree
from sklearn import preprocessing
import numpy
import csv
import pickle
import time
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.linear_model import RandomizedLasso
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier
import json

#Given a single csv about features, 
#build the feature vector X.
def openMetrics(Dir, X):
	with open(Dir,'rb') as f:
		reader = csv.reader(f)
		next(reader, None)
		for row in reader:
			row_data = []
			for i in row[1:]:
				row_data.append(float(i))
			X.append(row_data)
	f.close()


#Given a single csv file about label, read it 
#and build input array Y for fitting, as well as maps.
def openLabel(Dirl, Y, m, m_label):
	with open(Dirl,'rb') as f:
		reader = csv.reader(f)
		i = 0
		for row in reader:
			if row[1] in m:
				Y.append(m.get(row[1]))
			else:
				m[row[1]] = i
				m_label[i] = row[1]
				i+=1
				Y.append(m.get(row[1]))
	f.close()


#Function to build the map whose key is feature name and value is a unique integer
def build_map(m_feature):
	with open('../../data/raw_csv/1_features.csv','rb') as f:
		first_line = f.readline().split(",")
		j = 0
		for i in first_line[1:]:
			if "\n" in i:
				i = i[:-1]
			m_feature[i] = j
			j += 1
	f.close()

# X = numpy.log(1 + X)
# X = preprocessing.scale(X)



#Function used to save object to a pickle file
def save(model, file_name):
	with open(file_name, 'wb') as output:
		pickle.dump(model, output, pickle.HIGHEST_PROTOCOL)




#Train the models and save them as pickle file
def train():
	X = []
	Y = []
	testX = []
	testY = []
	m = dict()
	m_label = dict()
	m_feature = dict()

	# Generate input (X, Y) for the model as well as maps (m, m_label) for further use.
	for i in range(1,8):
		dirm = '../../data/raw_csv/%s_features.csv' % str(i)
		dirl = '../../data/raw_csv/%s_label.csv' % str(i)
		openMetrics(dirm, X)
		openLabel(dirl, Y, m, m_label)

	for j in range(8,11):
		dirmt = '../../data/raw_csv/%s_features.csv' % str(i)
		dirlt = '../../data/raw_csv/%s_label.csv' % str(i)
		openMetrics(dirmt, testX)
		openLabel(dirlt, testY, m, m_label)
	

	# Fit and train models
	#Train the randomized_lasso
	r_Lasso = RandomizedLasso(max_iter = 50)
	r_Lasso.fit(X, Y)

	#Train the random_forest
	forest = ExtraTreesClassifier(n_estimators=25, random_state=0)
	forest.fit(X, Y)
	score_forest = forest.score(testX,testY)
	print "score_forest = %f" %score_forest

	#Train random forest model 2, change parameters
	forest1 = ExtraTreesClassifier(n_estimators= 50, max_depth= 50, random_state = 50)
	forest1.fit(X, Y)
	score_forest1 = forest1.score(testX,testY)
	print "score_forest1 = %f" %score_forest1
	
	#Train randomized lasso model 2, change parameters
	r_Lasso1 = RandomizedLasso(max_iter = 1000, alpha= 0.1, random_state= 0)
	r_Lasso1.fit(X, Y)
	
	
	
	#Train decision tree model 1, change parameters
	clf = DecisionTreeClassifier(random_state=0, min_samples_split=4, min_samples_leaf=4)
	clf.fit(X,Y)
	score_clf = clf.score(testX, testY)
	print "score_clf = %f" %score_clf

	#Train decision tree model 2, change parameters
	clf1 = DecisionTreeClassifier(random_state=0, presort=True)
	clf1.fit(X,Y)
	score_clf1 = clf1.score(X, Y) 
	print "score_clf1 = %f" %score_clf1
	
	
	
	build_map(m_feature)
	
	#Save trained models and maps as pickle files.
	save(m_feature, '../../data/maps/feature_map.pkl')
	save(forest, '../../data/models/random_forest_n_estimators_25.pkl')
	save(m_label,'../../data/maps/get_label_map.pkl')
	save(r_Lasso, '../../data/models/randomized_lasso_max_iter_50.pkl')

	save(forest1,'../../data/models/random_forest_n_estimators_50.pkl')
	save(r_Lasso1,'../../data/models/randomized_lasso_max_iter_1000.pkl')
	save(clf,'../../data/models/decision_tree_min_samples_split_4.pkl')
	save(clf1,'../../data/models/decision_tree1_pre_sort_true.pkl')
	

if __name__ == '__main__':
	train()
	print "Done with model training"
